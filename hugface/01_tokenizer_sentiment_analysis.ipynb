{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. tokenizer -> construct input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tokenizer, model: match -> tokenizer outputs == model input\n",
    "- Auto\\*Tokenizer, AutoModel\\*：Generic type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:35:23.828856Z",
     "start_time": "2022-06-19T02:35:23.825866Z"
    }
   },
   "outputs": [],
   "source": [
    "test_senteces = ['today is not that bad', 'today is so bad']\n",
    "model_name = 'distilbert-base-uncased-finetuned-sst-2-english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:20:03.633366Z",
     "start_time": "2022-06-19T02:19:58.789769Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizer\n",
    "- tokenizer：serves model input\n",
    "    - len(input_ids) == len(attention_mask)\n",
    "    - tokenizer(test_senteces[0], ): tokenizer.\\_\\_call\\_\\_：encode\n",
    "    - tokenizer.encode == tokenizer.tokenize + tokenizer.convert_tokens_to_ids\n",
    "    - tokenizer.decode\n",
    "    - Principle of tokenizer is tokenizer.vocab stores token => id mapping relationship.\n",
    "        - tokenizer.special_tokens_map\n",
    "    - attention mask and padding match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:21:21.136712Z",
     "start_time": "2022-06-19T02:21:07.860869Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:23:20.499775Z",
     "start_time": "2022-06-19T02:23:20.495749Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_input = tokenizer(test_senteces, truncation=True, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:23:51.629797Z",
     "start_time": "2022-06-19T02:23:51.624465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2651, 2003, 2025, 2008, 2919,  102],\n",
       "        [ 101, 2651, 2003, 2061, 2919,  102,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 0]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:24:27.711057Z",
     "start_time": "2022-06-19T02:24:27.705957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2651, 2003, 2025, 2008, 2919, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(test_senteces[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:26:02.232367Z",
     "start_time": "2022-06-19T02:26:02.227981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2651, 2003, 2025, 2008, 2919, 102]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(test_senteces[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:27:01.802959Z",
     "start_time": "2022-06-19T02:27:01.798355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2651, 2003, 2025, 2008, 2919]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(test_senteces[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:28:38.186096Z",
     "start_time": "2022-06-19T02:28:38.180739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] today is not that bad [SEP]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([101, 2651, 2003, 2025, 2008, 2919, 102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:31:37.843855Z",
     "start_time": "2022-06-19T02:31:37.838167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:31:17.531347Z",
     "start_time": "2022-06-19T02:31:17.525170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 102, 0, 101, 103]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids([special for special in tokenizer.special_tokens_map.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:37:00.609769Z",
     "start_time": "2022-06-19T02:37:00.605463Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_input = tokenizer(test_senteces, truncation=True, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. model -> call model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:38:19.070764Z",
     "start_time": "2022-06-19T02:38:19.068147Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.config\n",
    "- find the func which convert id to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:39:56.465031Z",
     "start_time": "2022-06-19T02:39:56.459505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForSequenceClassification\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"finetuning_task\": \"sst-2\",\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"NEGATIVE\",\n",
       "    \"1\": \"POSITIVE\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"label2id\": {\n",
       "    \"NEGATIVE\": 0,\n",
       "    \"POSITIVE\": 1\n",
       "  },\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"tie_weights_\": true,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.55.4\",\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:40:46.821090Z",
     "start_time": "2022-06-19T02:40:46.723297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-3.4620,  3.6118],\n",
      "        [ 4.7508, -3.7899]]), hidden_states=None, attentions=None)\n",
      "tensor([[8.4631e-04, 9.9915e-01],\n",
      "        [9.9980e-01, 1.9531e-04]])\n",
      "tensor([1, 0])\n",
      "['POSITIVE', 'NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**batch_input)\n",
    "    print(outputs)\n",
    "    \n",
    "    scores = F.softmax(outputs.logits, dim=1)\n",
    "    print(scores)\n",
    "    \n",
    "    labels = torch.argmax(scores, dim=1)\n",
    "    print(labels)\n",
    "    \n",
    "    labels = [model.config.id2label[id] for id in labels.tolist()]\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:10:28.942776Z",
     "start_time": "2022-06-19T02:10:28.939489Z"
    }
   },
   "source": [
    "# 3. parse output -> output parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:40:57.429808Z",
     "start_time": "2022-06-19T02:40:57.328151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-3.4620,  3.6118],\n",
      "        [ 4.7508, -3.7899]]), hidden_states=None, attentions=None)\n",
      "tensor([[8.4631e-04, 9.9915e-01],\n",
      "        [9.9980e-01, 1.9531e-04]])\n",
      "tensor([1, 0])\n",
      "['POSITIVE', 'NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**batch_input)\n",
    "    print(outputs)\n",
    "    \n",
    "    scores = F.softmax(outputs.logits, dim=1)\n",
    "    print(scores)\n",
    "    \n",
    "    labels = torch.argmax(scores, dim=1)\n",
    "    print(labels)\n",
    "    \n",
    "    labels = [model.config.id2label[id] for id in labels.tolist()]\n",
    "    print(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (bert)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
